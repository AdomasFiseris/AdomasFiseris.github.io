{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":104383,"databundleVersionId":12957508,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### ModernBERT Reference  \nWarner et al., “Smarter, Better, Faster, Longer: A Modern Bidirectional Encoder…”, arXiv:2412.13663 (2024).\n\n@misc{modernbert,\n  title={Smarter, Better, Faster, Longer: A Modern Bidirectional Encoder for Fast, Memory Efficient, and Long Context Finetuning and Inference},\n  author={Benjamin Warner and Antoine Chaffin and Benjamin Clavié and Orion Weller and Oskar Hallström and Said Taghadouini and Alexis Gallagher and Raja Biswas and Faisal Ladhak and Tom Aarsen and Nathan Cooper and Griffin Adams and Jeremy Howard and Iacopo Poli},\n  year={2024},\n  eprint={2412.13663},\n  archivePrefix={arXiv},\n  primaryClass={cs.CL},\n  url={https://arxiv.org/abs/2412.13663}\n}","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2025-08-03T18:29:29.759400Z","iopub.execute_input":"2025-08-03T18:29:29.759691Z","iopub.status.idle":"2025-08-03T18:29:33.632553Z","shell.execute_reply.started":"2025-08-03T18:29:29.759653Z","shell.execute_reply":"2025-08-03T18:29:33.631553Z"}}},{"cell_type":"code","source":"os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\nos.environ[\"XLA_FLAGS\"] = \"--xla_gpu_cuda_data_dir=/tmp\"\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"                  \n\nimport os, datetime, warnings, re, unicodedata\nimport pandas as pd\nfrom sklearn.model_selection import StratifiedKFold\n\nimport torch\nimport torch.optim as optim\nfrom torch import nn\nfrom torch.utils.tensorboard import SummaryWriter\nfrom torch.utils.data import DataLoader\nfrom transformers import AutoTokenizer, AutoModel, default_data_collator, get_linear_schedule_with_warmup\n\n# TensorBoard writer (PyTorch version)\nlogdir = os.path.join(\n    \"tb_logs\",\n    \"run_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n)\nos.makedirs(logdir, exist_ok=True)\nwriter = SummaryWriter(logdir)\nprint(f\"TensorBoard logs → {logdir}\")\n\n# Inspect input files\nfor dirname, _, filenames in os.walk(\"/kaggle/input\"):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Load training CSV\ndf = pd.read_csv(\n    \"/kaggle/input/map-charting-student-math-misunderstandings/train.csv\"\n)\npd.set_option(\"display.max_colwidth\", None)\n\n# Device info\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Running on:\", device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T22:02:53.894612Z","iopub.execute_input":"2025-08-03T22:02:53.895106Z","iopub.status.idle":"2025-08-03T22:02:54.048117Z","shell.execute_reply.started":"2025-08-03T22:02:53.895077Z","shell.execute_reply":"2025-08-03T22:02:54.047317Z"}},"outputs":[{"name":"stdout","text":"TensorBoard logs → tb_logs/run_20250803-220253\n/kaggle/input/map-charting-student-math-misunderstandings/sample_submission.csv\n/kaggle/input/map-charting-student-math-misunderstandings/train.csv\n/kaggle/input/map-charting-student-math-misunderstandings/test.csv\nRunning on: cuda\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# 0. helper to normalise whitespace/Unicode\ndef _clean(txt: str) -> str:\n    txt = unicodedata.normalize(\"NFKC\", txt)\n    txt = re.sub(r\"\\s+\", \" \", txt)\n    return txt.strip()\n\n# 1. minimal preprocessing\ndef preprocess(df: pd.DataFrame) -> pd.DataFrame:\n    df = df.copy()\n\n    # text fields\n    df[\"StudentExplanation\"] = (\n        df[\"StudentExplanation\"].fillna(\"\").apply(_clean)\n    )\n    df[\"QuestionText\"] = df[\"QuestionText\"].apply(_clean)\n    df[\"MC_Answer\"]    = df[\"MC_Answer\"].apply(_clean)\n\n    # misconception field\n    df[\"Misconception\"] = (\n        df[\"Misconception\"]\n          .fillna(\"NA\")\n          .astype(str)\n          .str.strip()\n          .replace({\"Wrong_fraction\": \"Wrong_Fraction\"})\n    )\n    mask = df[\"Category\"].str.endswith(\"Misconception\")\n    df.loc[~mask, \"Misconception\"] = \"NA\"\n\n    # joint label string\n    df[\"label_str\"] = df[\"Category\"] + \":\" + df[\"Misconception\"]\n    return df\n\n# 2. build label maps + attach label_id\ndef build_label_maps(df: pd.DataFrame):\n    labels = sorted(df[\"label_str\"].unique())\n    label2id = {lbl: i for i, lbl in enumerate(labels)}\n    id2label = {i: lbl for lbl, i in label2id.items()}\n    df[\"label_id\"] = df[\"label_str\"].map(label2id).astype(int)\n    return df, label2id, id2label\n\n# 3. run the pipeline\ndf = preprocess(df)                     \ndf, label2id, id2label = build_label_maps(df)   \n\n# 4. stratified group K-fold on QuestionId\nwarnings.filterwarnings(\"ignore\", message=\"The least populated class\")\n\nk = 5\nskf = StratifiedKFold(\n    n_splits=k,\n    shuffle=True,\n    random_state=42\n)\n\ndf[\"fold\"] = -1\nfor fold, (_, val_idx) in enumerate(skf.split(df, y=df[\"label_id\"])):\n    df.loc[val_idx, \"fold\"] = fold\n\n# sanity check\nassert (df[\"fold\"] >= 0).all()\nprint(df[\"fold\"].value_counts().sort_index())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T21:54:48.050842Z","iopub.execute_input":"2025-08-03T21:54:48.051394Z","iopub.status.idle":"2025-08-03T21:54:48.616009Z","shell.execute_reply.started":"2025-08-03T21:54:48.051370Z","shell.execute_reply":"2025-08-03T21:54:48.615356Z"}},"outputs":[{"name":"stdout","text":"fold\n0    7340\n1    7339\n2    7339\n3    7339\n4    7339\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# 5. loading ModernBERT tokenizer\nMODEL_NAME = 'answerdotai/ModernBERT-base'\nNUM_LABELS = len(label2id)\nMAX_LEN = 128\n\n# 6. fast tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\n    MODEL_NAME,\n    use_fast=True\n)\n\n# 7. template builder\nTEMPLATE = \"{q} [SEP] {a} [SEP] {e}\"\n\ndef build_text(row):\n    return TEMPLATE.format(\n        q=row[\"QuestionText\"],\n        a=row[\"MC_Answer\"],\n        e=row[\"StudentExplanation\"]\n    )\n\ndf[\"text\"] = df.apply(build_text, axis=1)\n\n# 8. sampling sequence lenght distribution\ntok_lens = df[\"text\"].apply(lambda s: len(tokenizer.tokenize(s)))\nprint(tok_lens.describe(percentiles=[.5,.75,.9,.95,.99]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T21:54:52.789062Z","iopub.execute_input":"2025-08-03T21:54:52.789778Z","iopub.status.idle":"2025-08-03T21:54:59.958277Z","shell.execute_reply.started":"2025-08-03T21:54:52.789746Z","shell.execute_reply":"2025-08-03T21:54:59.957629Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"984ca936a6ef49ec88b9474434a44b00"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c22b838162384d6e92299717617e278d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/694 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e87e3672ab5d4a3d942c57032d499f53"}},"metadata":{}},{"name":"stdout","text":"count    36696.000000\nmean        56.639825\nstd         18.143780\nmin         19.000000\n50%         55.000000\n75%         67.000000\n90%         80.000000\n95%         92.000000\n99%        108.000000\nmax        215.000000\nName: text, dtype: float64\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# 9. PyTorch Dataset\nclass MAPDataset(torch.utils.data.Dataset):\n    def __init__(self, frame):\n        self.texts = frame[\"text\"].tolist()\n        self.labels = frame[\"label_id\"].tolist()\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        enc = tokenizer(\n            self.texts[idx],\n            padding=\"max_length\",\n            truncation=True,\n            max_length=MAX_LEN,\n            return_attention_mask=True,\n            return_token_type_ids=True,\n        )\n        item = {\n            \"input_ids\": torch.tensor(enc[\"input_ids\"], dtype=torch.long),\n            \"attention_mask\": torch.tensor(enc[\"attention_mask\"], dtype=torch.long),\n            \"token_type_ids\": torch.tensor(enc[\"token_type_ids\"], dtype=torch.long),\n            \"labels\": torch.tensor(self.labels[idx], dtype=torch.long),\n        }\n        return item\n\n# 10. dataframe → DataLoader\ndef make_loader(frame, batch_size=16, shuffle=True):\n    ds = MAPDataset(frame)                           \n    return DataLoader(\n        ds,\n        batch_size=batch_size,\n        shuffle=shuffle,           \n        num_workers=2,                               \n        pin_memory=True\n    )\n\n# 11. choose one validation fold\nval_fold = 4                                         \n\ntrain_df = df[df[\"fold\"] != val_fold].reset_index(drop=True)\nval_df = df[df[\"fold\"] == val_fold].reset_index(drop=True)\nprint(len(train_df), \"train rows |\", len(val_df), \"val rows\")\n\ntrain_loader = make_loader(train_df, batch_size=16, shuffle=True)\nval_loader = make_loader(val_df, batch_size=32, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T21:55:05.292069Z","iopub.execute_input":"2025-08-03T21:55:05.292642Z","iopub.status.idle":"2025-08-03T21:55:05.324027Z","shell.execute_reply.started":"2025-08-03T21:55:05.292615Z","shell.execute_reply":"2025-08-03T21:55:05.323373Z"}},"outputs":[{"name":"stdout","text":"29357 train rows | 7339 val rows\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"MODEL_NAME  = \"answerdotai/ModernBERT-base\"   \nHIDDEN_SIZE = 768                             \nNUM_LABELS = len(label2id)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# 12. ModernBERT + single-layer classification head\nclass ModernBertClassifier(nn.Module):\n    def __init__(self, num_labels=NUM_LABELS, dropout=0.1):\n        super().__init__()\n        self.encoder = AutoModel.from_pretrained(MODEL_NAME)\n        self.dropout = nn.Dropout(dropout)\n        self.classifier = nn.Linear(self.encoder.config.hidden_size, num_labels)\n\n    def forward(self, input_ids, attention_mask=None, token_type_ids=None, labels=None):\n        out = self.encoder(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            token_type_ids=token_type_ids,\n        )\n        cls_vec  = out.last_hidden_state[:, 0]         \n        logits   = self.classifier(self.dropout(cls_vec))\n\n        loss = None\n        if labels is not None:\n            loss = nn.functional.cross_entropy(logits, labels)\n\n        return {\"logits\": logits, \"loss\": loss}\n\n# 13. Factory that returns model, optimizer, scheduler\ndef build_model(total_train_steps, lr=2e-5, weight_decay=0.01, warmup_ratio=0.1):\n\n    model = ModernBertClassifier().to(device)\n\n    # weight-decay only on non-bias / non-LayerNorm weights\n    no_decay = [\"bias\", \"LayerNorm.weight\"]\n    param_groups = [\n        {\n            \"params\": [p for n, p in model.named_parameters()\n                       if not any(nd in n for nd in no_decay)],\n            \"weight_decay\": weight_decay,\n        },\n        {\n            \"params\": [p for n, p in model.named_parameters()\n                       if any(nd in n for nd in no_decay)],\n            \"weight_decay\": 0.0,\n        },\n    ]\n\n    optimizer = optim.AdamW(param_groups, lr=lr)\n    scheduler = get_linear_schedule_with_warmup(\n        optimizer,\n        num_warmup_steps=int(total_train_steps * warmup_ratio),\n        num_training_steps=total_train_steps,\n    )\n\n    return model, optimizer, scheduler","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T21:55:09.303327Z","iopub.execute_input":"2025-08-03T21:55:09.303871Z","iopub.status.idle":"2025-08-03T21:55:09.311532Z","shell.execute_reply.started":"2025-08-03T21:55:09.303846Z","shell.execute_reply":"2025-08-03T21:55:09.310854Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"epochs = 5\ntotal_steps = len(train_loader) * epochs\nmodel, optim, sched = build_model(total_train_steps=total_steps)\n\nfor epoch in range(epochs):\n    model.train()\n    running = 0.0\n\n    for batch in train_loader:\n        batch = {k: v.to(device) for k, v in batch.items()}\n\n        out = model(**batch)\n        loss = out[\"loss\"]\n\n        loss.backward()\n        optim.step()\n        sched.step()\n        optim.zero_grad()\n\n        running += loss.item()\n\n    avg_train = running / len(train_loader)\n    writer.add_scalar(\"Loss/train\", avg_train, epoch)\n\n    # validation\n    model.eval()\n    val_running, preds, y_true = 0.0, [], []\n\n    with torch.no_grad():\n        for batch in val_loader:\n            batch = {k: v.to(device) for k, v in batch.items()}\n            out = model(**batch)\n\n            val_running += out[\"loss\"].item()\n            preds.append(out[\"logits\"].cpu().numpy())\n            y_true.extend(batch[\"labels\"].cpu().numpy())\n\n    avg_val = val_running / len(val_loader)\n    writer.add_scalar(\"Loss/val\", avg_val, epoch)\n\n    # quick MAP@3\n    import numpy as np\n    preds = np.vstack(preds)\n    top3  = preds.argsort(axis=1)[:, -3:][:, ::-1]\n    map3  = np.mean([\n        1/(row.tolist().index(y)+1) if y in row else 0\n        for y, row in zip(y_true, top3)\n    ])\n    writer.add_scalar(\"MAP3/val\", map3, epoch)\n\n    print(f\"Epoch {epoch+1}: train_loss={avg_train:.4f}  \"\n          f\"val_loss={avg_val:.4f}  MAP@3={map3:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}